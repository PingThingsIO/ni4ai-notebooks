{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with StreamSets\n",
    "\n",
    "In this notebook we will focus on retrieving data from groups of time series streams (a `StreamSet`) as opposed to concentrating on individual streams.  You can think of a `StreamSet` as a wrapper around a list of `Stream` objects as found in the preceding notebook.\n",
    "\n",
    "The StreamSet class has a number of methods to mirror those found in regular Stream objects including methods for transforming and serializing the data to different formats. \n",
    "\n",
    "As with a `Stream`, retrieving data from the BTrDB server will fully materialize in memory so please keep this in mind.  In other words, do not attempt to retreive data that is greater than the amount of memory available to you.\n",
    "\n",
    "If you would like to learn more about any of the topics covered here, please see the btrdb library [documentation](https://btrdb.readthedocs.io/en/develop/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import btrdb\n",
    "from tabulate import tabulate\n",
    "from btrdb.utils.timez import ns_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect To Server\n",
    "\n",
    "To get started we'll connect to the server and define a helper method from a previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'majorVersion': 5, 'build': '5.1.10', 'proxy': {'proxyEndpoints': []}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = btrdb.connect(apikey=\"AE0C013A87C48930E37ED8D8\")\n",
    "conn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_streams(streams):\n",
    "    table = [[\"Collection\", \"Name\", \"Units\", \"Version\", \"Earliest\", \"Latest\"]]\n",
    "    for stream in streams:\n",
    "        tags = stream.tags()\n",
    "        table.append([\n",
    "            stream.collection, stream.name, tags[\"unit\"], stream.version(), \n",
    "            stream.earliest()[0].time, stream.latest()[0].time, \n",
    "        ])\n",
    "    return tabulate(table, headers=\"firstrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Methods\n",
    "\n",
    "The best way to think about the `StreamSet` is as a wrapper around a list of `Stream` objects with appropriate methods added to help with examining your data. To create a `StreamSet` we first need the UUIDs for streams, which we will obtain by selecting a few voltage streams from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection              Name           Units      Version             Earliest               Latest\n",
      "----------------------  -------------  -------  ---------  -------------------  -------------------\n",
      "relay/Possum Po_11-1L1  LINE560V1-MAG  Volts          942  1536710401000000000  1538265599000000000\n",
      "relay/Possum Po_11-1L1  LINE560VA-MAG  Volts          942  1536710401000000000  1538265599000000000\n",
      "relay/Possum Po_11-1L1  LINE560VB-MAG  Volts          942  1536710401000000000  1538265599000000000\n",
      "relay/Possum Po_11-1L1  LINE560VC-MAG  Volts          942  1536710401000000000  1538265599000000000\n"
     ]
    }
   ],
   "source": [
    "streams = conn.streams_in_collection('relay/Possum Po_11-1L1', tags={\"unit\": \"Volts\"})\n",
    "streams = list(streams)\n",
    "print(describe_streams(streams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a `StreamSet` using the UUIDs from our known streams.  In the future, we will be able to query based on collection, tags, etc., but for now we need to provide the UUIDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UUID('1027914c-b84a-43e9-9f6e-f04f6e006dbc'),\n",
       " UUID('171facf4-fdb3-4589-9404-37fe705f46d3'),\n",
       " UUID('44c8db28-18b8-4f12-9a22-7b062d8e646c'),\n",
       " UUID('af8cf764-6f04-4f9b-b25b-467778bc5320')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UUIDs = [s.uuid for s in streams]\n",
    "UUIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StreamSet(4 streams)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset = conn.streams(*UUIDs)\n",
    "streamset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a StreamSet with the four streams, let's take a look at some of the helper methods.  In a Stream object, the `earliest` method would provide the first point in the Stream.  `StreamSet.earliest` will provide a tuple containing the first points from each individual stream.  The order is the same as the UUIDs that were provided when creating the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RawPoint(1536710401000000000, 302817.8),\n",
       " RawPoint(1536710401000000000, 303338.4),\n",
       " RawPoint(1536710401000000000, 303071.1),\n",
       " RawPoint(1536710401000000000, 302053.4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset.earliest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, let's look at the latest points in the streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RawPoint(1538265599000000000, 303385.6),\n",
       " RawPoint(1538265599000000000, 304196.8),\n",
       " RawPoint(1538265599000000000, 303723.8),\n",
       " RawPoint(1538265599000000000, 302253.8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset.latest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing Data\n",
    "\n",
    "Like the `Stream` object, the `StreamSet` has a `values` method which will return a list of lists.  Each internal list contains the `RawPoint` instances for a given stream.  Just as before we will return only a little bit of the data from the beginning of the streams.\n",
    "\n",
    "We will start by finding the earliest time from all of the earliest points although in this case they all have the same beginning time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536710401000000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliest_point = sorted(streamset.earliest(), key=lambda p: p.time)[0]\n",
    "earliest_point.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will ask for the values in the streams. Stream values are returned as a list of list of points such that the lists of points are ordered according to the UUIDs provided on initialization. Using this method data is fetched for each stream and returned and can be thought of as a helper method to query multiple streams simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[RawPoint(1536710401000000000, 302817.8),\n",
       "  RawPoint(1536710401033000000, 302907.3),\n",
       "  RawPoint(1536710401066000000, 302823.3)],\n",
       " [RawPoint(1536710401000000000, 303338.4),\n",
       "  RawPoint(1536710401033000000, 303431.7),\n",
       "  RawPoint(1536710401066000000, 303366.3)],\n",
       " [RawPoint(1536710401000000000, 303071.1),\n",
       "  RawPoint(1536710401033000000, 303146.9),\n",
       "  RawPoint(1536710401066000000, 303067.3)],\n",
       " [RawPoint(1536710401000000000, 302053.4),\n",
       "  RawPoint(1536710401033000000, 302126.9),\n",
       "  RawPoint(1536710401066000000, 302050.7)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = earliest_point.time\n",
    "end = start + ns_delta(milliseconds=100)\n",
    "streamset.filter(start, end).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that we first called the `filter` method and then called the `values` method with no arguments.  The `StreamSet` class was designed to support a method chaining style of programming and so behaves slightly differently from the `Stream`.\n",
    "\n",
    "Data is only ever materialized when calling the `values` or `rows` method as demonstrated below.  The `rows` method is similar to the `values` method but orients the data differently.  Here you will notice that the streams are aligned according to time.  The first tuple contains all of the data for the first time index.  If any streams do not have data at that time index, then `None` is used as a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(RawPoint(1536710401000000000, 302817.8),\n",
       "  RawPoint(1536710401000000000, 303338.4),\n",
       "  RawPoint(1536710401000000000, 303071.1),\n",
       "  RawPoint(1536710401000000000, 302053.4)),\n",
       " (RawPoint(1536710401033000000, 302907.3),\n",
       "  RawPoint(1536710401033000000, 303431.7),\n",
       "  RawPoint(1536710401033000000, 303146.9),\n",
       "  RawPoint(1536710401033000000, 302126.9)),\n",
       " (RawPoint(1536710401066000000, 302823.3),\n",
       "  RawPoint(1536710401066000000, 303366.3),\n",
       "  RawPoint(1536710401066000000, 303067.3),\n",
       "  RawPoint(1536710401066000000, 302050.7))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset.filter(start, end).rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the tabulate library again to better format the data rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               time    LINE560V1-MAG    LINE560VA-MAG    LINE560VB-MAG    LINE560VC-MAG\n",
      "-------------------  ---------------  ---------------  ---------------  ---------------\n",
      "1536710401000000000           302818           303338           303071           302053\n",
      "1536710401033000000           302907           303432           303147           302127\n",
      "1536710401066000000           302823           303366           303067           302051\n"
     ]
    }
   ],
   "source": [
    "table = [[\"time\"] + [s.name for s in streamset]]\n",
    "\n",
    "for row in streamset.filter(start, end).rows():\n",
    "    time = sorted([p.time for p in row])[-1]\n",
    "    data = [time]\n",
    "    for point in row:\n",
    "        data.append(point.value)\n",
    "    table.append(data)\n",
    "        \n",
    "print(tabulate(table, headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Data to Other Formats\n",
    "\n",
    "A number of methods have been provided to convert the point data objects into objects you may already be familiar with such as numpy arrays and pandas dataframes.  Using these transformation methods materializes the data similar to the `values` method.  Examples of the available transformations follow.\n",
    "\n",
    "## Numpy Arrays\n",
    "\n",
    "Converting to Numpy arrays will produce a list of arrays.  This output will be similar in structure to calling the `values` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([RawPoint(1536710401000000000, 302817.8),\n",
       "        RawPoint(1536710401033000000, 302907.3),\n",
       "        RawPoint(1536710401066000000, 302823.3)], dtype=object),\n",
       " array([RawPoint(1536710401000000000, 303338.4),\n",
       "        RawPoint(1536710401033000000, 303431.7),\n",
       "        RawPoint(1536710401066000000, 303366.3)], dtype=object),\n",
       " array([RawPoint(1536710401000000000, 303071.1),\n",
       "        RawPoint(1536710401033000000, 303146.9),\n",
       "        RawPoint(1536710401066000000, 303067.3)], dtype=object),\n",
       " array([RawPoint(1536710401000000000, 302053.4),\n",
       "        RawPoint(1536710401033000000, 302126.9),\n",
       "        RawPoint(1536710401066000000, 302050.7)], dtype=object)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = earliest_point.time\n",
    "end = start + ns_delta(milliseconds=100)\n",
    "\n",
    "streamset.filter(start, end).to_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Series\n",
    "\n",
    "Converting to a pandas series will produce a view of the data similar to calling the `values` method.  The resulting series will be indexed by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1536710401000000000    302817.8\n",
       " 1536710401033000000    302907.3\n",
       " 1536710401066000000    302823.3\n",
       " dtype: float64, 1536710401000000000    303338.4\n",
       " 1536710401033000000    303431.7\n",
       " 1536710401066000000    303366.3\n",
       " dtype: float64, 1536710401000000000    303071.1\n",
       " 1536710401033000000    303146.9\n",
       " 1536710401066000000    303067.3\n",
       " dtype: float64, 1536710401000000000    302053.4\n",
       " 1536710401033000000    302126.9\n",
       " 1536710401066000000    302050.7\n",
       " dtype: float64]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset.filter(start, end).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrame\n",
    "\n",
    "Converting to a pandas dataframe will produce a tabular view of the data similar to calling the `rows` method.  The resulting dataframe will be indexed by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relay/Possum Po_11-1L1/LINE560V1-MAG</th>\n",
       "      <th>relay/Possum Po_11-1L1/LINE560VA-MAG</th>\n",
       "      <th>relay/Possum Po_11-1L1/LINE560VB-MAG</th>\n",
       "      <th>relay/Possum Po_11-1L1/LINE560VC-MAG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1536710401000000000</th>\n",
       "      <td>302817.8</td>\n",
       "      <td>303338.4</td>\n",
       "      <td>303071.1</td>\n",
       "      <td>302053.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536710401033000000</th>\n",
       "      <td>302907.3</td>\n",
       "      <td>303431.7</td>\n",
       "      <td>303146.9</td>\n",
       "      <td>302126.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536710401066000000</th>\n",
       "      <td>302823.3</td>\n",
       "      <td>303366.3</td>\n",
       "      <td>303067.3</td>\n",
       "      <td>302050.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     relay/Possum Po_11-1L1/LINE560V1-MAG  \\\n",
       "time                                                        \n",
       "1536710401000000000                              302817.8   \n",
       "1536710401033000000                              302907.3   \n",
       "1536710401066000000                              302823.3   \n",
       "\n",
       "                     relay/Possum Po_11-1L1/LINE560VA-MAG  \\\n",
       "time                                                        \n",
       "1536710401000000000                              303338.4   \n",
       "1536710401033000000                              303431.7   \n",
       "1536710401066000000                              303366.3   \n",
       "\n",
       "                     relay/Possum Po_11-1L1/LINE560VB-MAG  \\\n",
       "time                                                        \n",
       "1536710401000000000                              303071.1   \n",
       "1536710401033000000                              303146.9   \n",
       "1536710401066000000                              303067.3   \n",
       "\n",
       "                     relay/Possum Po_11-1L1/LINE560VC-MAG  \n",
       "time                                                       \n",
       "1536710401000000000                              302053.4  \n",
       "1536710401033000000                              302126.9  \n",
       "1536710401066000000                              302050.7  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset.filter(start, end).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Dictionaries\n",
    "\n",
    "Converting to Python dictionaries produces a list of `OrderedDicts` similar to calling the `rows` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('time', 1536710401000000000),\n",
       "              ('relay/Possum Po_11-1L1/LINE560V1-MAG', 302817.8),\n",
       "              ('relay/Possum Po_11-1L1/LINE560VA-MAG', 303338.4),\n",
       "              ('relay/Possum Po_11-1L1/LINE560VB-MAG', 303071.1),\n",
       "              ('relay/Possum Po_11-1L1/LINE560VC-MAG', 302053.4)]),\n",
       " OrderedDict([('time', 1536710401033000000),\n",
       "              ('relay/Possum Po_11-1L1/LINE560V1-MAG', 302907.3),\n",
       "              ('relay/Possum Po_11-1L1/LINE560VA-MAG', 303431.7),\n",
       "              ('relay/Possum Po_11-1L1/LINE560VB-MAG', 303146.9),\n",
       "              ('relay/Possum Po_11-1L1/LINE560VC-MAG', 302126.9)]),\n",
       " OrderedDict([('time', 1536710401066000000),\n",
       "              ('relay/Possum Po_11-1L1/LINE560V1-MAG', 302823.3),\n",
       "              ('relay/Possum Po_11-1L1/LINE560VA-MAG', 303366.3),\n",
       "              ('relay/Possum Po_11-1L1/LINE560VB-MAG', 303067.3),\n",
       "              ('relay/Possum Po_11-1L1/LINE560VC-MAG', 302050.7)])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset.filter(start, end).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serializing Data\n",
    "\n",
    "Aside from transforming to other data objects, you can also serialize the data to other formats.  At the moment, you can serialize the data to disk as CSV or to a string for display.\n",
    "\n",
    "## To CSV\n",
    "\n",
    "The `to_csv` method takes a filename string or a file-like object as a mandatory argument.  If a string is received, then it will save the data to disk as a CSV file.  If a file-like object is received, then it will write to that as an output stream.\n",
    "\n",
    "The example below uses the StringIO to mimic a file object.  If called with a regular string as a file name, then `None` is returned and a new file is created.  For this example, we will use only two streams for display purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time,relay/Possum Po_11-1L1/LINE560V1-MAG,relay/Possum Po_11-1L1/LINE560VA-MAG\n",
      "1536710401000000000,302817.8,303338.4\n",
      "1536710401033000000,302907.3,303431.7\n",
      "1536710401066000000,302823.3,303366.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "# create a new streamset with only 2 streams for better display in a notebook\n",
    "streamset = conn.streams(*UUIDs[:2])\n",
    "\n",
    "# create file-like object\n",
    "fake_file = StringIO()\n",
    "\n",
    "# call to_csv which will detect the output stream and write the data to it\n",
    "streamset.filter(start, end).to_csv(fake_file)\n",
    "\n",
    "# move back to beginning of file-like object and print contents\n",
    "fake_file.seek(0)\n",
    "print(fake_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note if you wanted to write this to a real file it would look something like:\n",
    "\n",
    "```python\n",
    "streamset = conn.streams(*UUIDs[:2])\n",
    "streamset.filter(start, end).to_csv(\"mydata.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Table\n",
    "\n",
    "Similar to our example code using the tabulate library, this will return a string containing a formatted table of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               time    relay/Possum Po_11-1L1/LINE560V1-MAG    relay/Possum Po_11-1L1/LINE560VA-MAG\n",
      "-------------------  --------------------------------------  --------------------------------------\n",
      "1536710401000000000                                  302818                                  303338\n",
      "1536710401033000000                                  302907                                  303432\n",
      "1536710401066000000                                  302823                                  303366\n"
     ]
    }
   ],
   "source": [
    "print(streamset.filter(start, end).to_table())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

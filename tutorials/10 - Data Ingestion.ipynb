{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion\n",
    "\n",
    "Inserting data into btrdb involves five core steps:\n",
    "1. Data loading \n",
    "2. Data manipulation\n",
    "3. Stream creation\n",
    "4. Inserting values\n",
    "5. Updating metadata\n",
    "\n",
    "This tutorial walks through each of these steps using a USGS dataset measuring the Earth's geomagnetic field. We'll use the USGS webservice to request and load the data, and then convert it into a format that can be inserted into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import btrdb\n",
    "import urllib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = btrdb.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = 'https://geomag.usgs.gov/ws/data/?id=USGS&format=json&sampling_period=1&starttime=2021-10-25T00:26:54.177Z&endtime=2021-10-25T12:26:54.177Z'\n",
    "data_str = urllib.request.urlopen(url).read()\n",
    "data_dict = json.loads(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = data_dict['metadata']\n",
    "timestamps = data_dict['times']\n",
    "stream_data = data_dict['values']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a UUID for each stream\n",
    "\n",
    "Here, we'll use the uuid python library to generate a new uuid for each of the streams we want to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "stream_uuids = [uuid.uuid4() for ix in range(len(stream_data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define information about each stream (i.e., `collection`, `annotations` and `tags`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = 'zz/insertion/example/usgs'\n",
    "\n",
    "stream_names = []\n",
    "annotations_dict = {}\n",
    "tags_dict = {}\n",
    "for stream in stream_data:\n",
    "    name = stream['id']\n",
    "    stream_names.append(name)\n",
    "    annotations_dict[name] = {**metadata, **stream['metadata']}\n",
    "    tags_dict[name] = {'name': name,'unit': 'nanoteslas'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert time stamps to nanoseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btrdb.utils.timez import datetime_to_ns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_datetime = lambda t: datetime.strptime(t, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "ns_times = [datetime_to_ns(to_datetime(t)) for t in timestamps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_objects = []\n",
    "for i, name in enumerate(stream_names):\n",
    "    try:\n",
    "        # To create a stream, we must specify various parameters\n",
    "        stream = db.create(stream_uuids[i], # UUID\n",
    "                           collection, # collection\n",
    "                           tags=tags_dict[name], # tags\n",
    "                           annotations=annotations_dict[name] # annotations\n",
    "                          )\n",
    "        \n",
    "        stream_objects.append(stream)\n",
    "        \n",
    "    # If a stream already exists with the UUID, trying to create it again will raise an error\n",
    "    except Exception as e:\n",
    "        if str(e) == 'a stream already exists with uuid %s'%(stream_uuids[i]):\n",
    "            # Here we'll query the database to retrieve the stream \n",
    "            #    so we can then insert data into it\n",
    "            stream = db.stream_from_uuid(stream_uuids[i])\n",
    "            stream_objects.append(stream)\n",
    "        else:\n",
    "            assert False, e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting values\n",
    "\n",
    "Each point in the database is a time-value pair. Just as database queries return a list of tuples describing the `[(time1, value1), (time2, value2), ...]`, data insertions follow the same structure.\n",
    "\n",
    "#### Merge policies\n",
    "\n",
    "When inserting data, you can specify one of several merge policies. Valid merge policies include\n",
    "- ’never’: the default, no points are merged\n",
    "- ’equal’: points are deduplicated if the time and value are equal\n",
    "- ’retain’: if two points have the same timestamp, the old one is kept\n",
    "- ’replace’: if two points have the same timestamp, the new one is kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stream, data in zip(stream_objects, stream_data):\n",
    "    points = list(zip(ns_times, data['values']))\n",
    "    stream.insert(points, merge='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating metadata\n",
    "\n",
    "It is often the case metadata needs to be added, updated, or further refined after a stream has already been created. This can be done using `stream.update()`.\n",
    "\n",
    "Here, we'll go through the process of adding a url to indicate where the data originated from. Note that there is a 'url' field in the raw metadata we had inserted previously, but the value was set to 'null'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'null',\n",
       " 'channel': 'X',\n",
       " 'station': 'USGS',\n",
       " 'element': 'X',\n",
       " 'network': 'NT',\n",
       " 'status': '200',\n",
       " 'location': 'A0',\n",
       " 'generated': '2021-12-10T21:39:06Z',\n",
       " 'intermagnet': '{\"imo\": {\"iaga_code\": \"USGS\", \"name\": \"USGS\", \"coordinates\": [254.764, 40.137, 1682.0]}, \"reported_orientation\": \"XYZF\", \"sensor_orientation\": \"HDZF\", \"data_type\": \"adjusted\", \"sampling_period\": 1, \"digital_sampling_rate\": 0.01}'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streams = db.streams_in_collection(collection)\n",
    "annotations, _ = streams[0].annotations()\n",
    "\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stream in streams:\n",
    "    new_annotations = {'url': url}\n",
    "    stream.update(annotations=new_annotations, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can query the stream's annotations again to confirm that the url has been stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://geomag.usgs.gov/ws/data/?id=USGS&format=json&sampling_period=1&starttime=2021-10-25T00:26:54.177Z&endtime=2021-10-25T12:26:54.177Z'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream.annotations()[0]['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on the keyword `replace`\n",
    "\n",
    "Setting `replace=False` above allowed us to insert/update a single metadata field, without touching metadata fields that were not in the `new_annotations` dictionary.\n",
    "\n",
    "If the intended behavior is to completely overhaul the metadata that was previously in place, you can do so by setting `replace=True`.\n",
    "\n",
    "Here, we'll go through an example that creates separate metadata fields for each fo the parameters stored in the `intermagnet` metadata field (see example above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stream in streams:\n",
    "    old_annotations, _ = stream.annotations()\n",
    "    intermagnet = old_annotations.pop('intermagnet')\n",
    "    imo = intermagnet.pop('imo')\n",
    "    new_annotations = {**old_annotations, **intermagnet, **imo}\n",
    "    \n",
    "    stream.update(annotations=new_annotations, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'location': 'A0',\n",
       "  'reported_orientation': 'XYZF',\n",
       "  'coordinates': [254.764, 40.137, 1682.0],\n",
       "  'iaga_code': 'USGS',\n",
       "  'channel': 'F',\n",
       "  'url': 'https://geomag.usgs.gov/ws/data/?id=USGS&format=json&sampling_period=1&starttime=2021-10-25T00:26:54.177Z&endtime=2021-10-25T12:26:54.177Z',\n",
       "  'station': 'USGS',\n",
       "  'data_type': 'adjusted',\n",
       "  'name': 'USGS',\n",
       "  'element': 'F',\n",
       "  'sensor_orientation': 'HDZF',\n",
       "  'digital_sampling_rate': 0.01,\n",
       "  'generated': '2021-12-10T21:39:06Z',\n",
       "  'network': 'NT',\n",
       "  'status': 200,\n",
       "  'sampling_period': 1},\n",
       " 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream.annotations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting over\n",
    "\n",
    "If you make a mistake, you can start with a clean state by obliterating the streams we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stream in db.streams_in_collection(collection):\n",
    "    stream.obliterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

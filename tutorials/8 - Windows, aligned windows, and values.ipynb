{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windows, aligned windows, and values\n",
    "\n",
    "This tutorial offers a guide on using the PredictiveGrid to work wtih VERY big data sets.\n",
    "\n",
    "When working with high-resolution time series data, seemingly simple tasks can quickly become intractable. The reason for this is that the volume of data exceeds the computational limits of most most computing environments.\n",
    "\n",
    "Here, we'll describe three methods for querying data in PredictiveGrid. In practice none of these is \"better\" than another -- there is a time and a place for each. This post will weigh the relative advantages of each approach.\n",
    "\n",
    "### Functions used\n",
    "- `stream.values()`\n",
    "- `stream.windows()`\n",
    "- `stream.aligned_windows()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import btrdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from btrdb.utils.timez import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = btrdb.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is \"Big Data\"?\n",
    "\n",
    "One definition of the term \"Big Data\" helps to put the problem in context:\n",
    "> The term “big data” refers to data that is so large, fast or complex that it’s difficult or impossible to process using traditional methods. \n",
    "\n",
    "Let's dig into what this means by looking at the size of the `sunshine` data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thats a total of 279.60 Billion points!\n"
     ]
    }
   ],
   "source": [
    "n_points = 0\n",
    "for stream in db.streams_in_collection('sunshine'):\n",
    "    n_points += stream.count()\n",
    "    \n",
    "print('Thats a total of %.2f Billion points!'%(n_points/1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much data is that?\n",
    "\n",
    "To illustrate what's meant by `BIG DATA`, let's investigate the very simple task of querying data from a single stream.\n",
    "\n",
    "Your first thought might be to say: `Give me all the data!` But what will that yield?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection:\t sunshine/PMU1\n",
      "stream name:\t L1MAG\n",
      "num points:\t 5.143168296 Billion\n"
     ]
    }
   ],
   "source": [
    "streams = db.streams_in_collection('sunshine/PMU1', tags={'name': 'L1MAG'})\n",
    "stream = streams[0]\n",
    "print('collection:\\t', stream.collection)\n",
    "print('stream name:\\t', stream.name)\n",
    "\n",
    "# How many points is that?\n",
    "print('num points:\\t', stream.count()/1e9, 'Billion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.14 Billion points is 82.29 gigabytes of data!\n"
     ]
    }
   ],
   "source": [
    "# What is that in gigabytes?\n",
    "print('%.2f Billion points is %.2f gigabytes of data!'%(stream.count()/1e9, stream.count()*64*2/8/1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's a lot of data!\n",
    "That volume of data will almost certainly overload your local computing environment. Even if you're working in the cloud, it would be expensive to maintain an envrionment with that much memory. It's worth checking that you need that much data before asking for an environment large enough to get it.\n",
    "\n",
    "Most importantly, it'll likely take quite a long time to get the data back to you. **Waiting for data is NOT worth your time**.\n",
    "\n",
    "##### What are the alternatives?\n",
    "\n",
    "Below, we've included a helper function for issuing different types of queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windows Queries\n",
    "\n",
    "Windows queries provide *statistical aggregates* or \"summary statistics\" of raw data points in a give ntime interval. A windows query will return a time series of `StatPoint` objetcs, which can be used to explore summary statistics of raw values over time.\n",
    "\n",
    "#### New to `StatPoints`? \n",
    "Start here: https://github.com/PingThingsIO/ni4ai-notebooks/blob/main/tutorials/5%20-%20Working%20with%20StatPoints.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 1.45 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = currently_as_ns()\n",
    "\n",
    "start, _ = stream.earliest()\n",
    "end, _ = stream.latest()\n",
    "\n",
    "window = ns_delta(days=5)\n",
    "statpoints = stream.windows(start.time, end.time, window)\n",
    "print('Runtime: %.2f seconds'%((currently_as_ns()-t0)/1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "\n",
    "The query `stream.windows()` scanned through 18 months of data to return `StatPoint` objects in intervals specified by `window`. Let's visualize the restults. \n",
    "\n",
    "It took less than 10 MICROseconds to run through all 18 months of data.\n",
    "\n",
    "***That's pretty fast***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens if we zoom in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 5.99 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = currently_as_ns()\n",
    "\n",
    "window = ns_delta(days=1)\n",
    "statpoints = stream.windows(start.time, end.time, window)\n",
    "print('Runtime: %.2f seconds'%((currently_as_ns()-t0)/1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 26.49 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = currently_as_ns()\n",
    "window = ns_delta(hours=6)\n",
    "statpoints = stream.windows(start.time, end.time, window)\n",
    "print('Runtime: %.2f seconds'%((currently_as_ns()-t0)/1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That one took a while! Don't worry, there's a better way.\n",
    "\n",
    "# Aligned windows\n",
    "\n",
    "Aligned windows return results that look very much like windows queries. The only differece, is that time stamps are adjusted to align with time windows stored inherently in the database. Where `windows` queries may need to re-compute statistical aggregates over the time window requested, `aligned_windows` queries can leverage pre-computed values.\n",
    "\n",
    "\n",
    "Let's look at the difference in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.04 seconds\n"
     ]
    }
   ],
   "source": [
    "window = ns_delta(hours=6)\n",
    "pw = np.log2(window)\n",
    "\n",
    "t0 = currently_as_ns()\n",
    "statpoints = stream.aligned_windows(start.time, end.time, pointwidth=pw)\n",
    "print('Runtime: %.2f seconds'%((currently_as_ns()-t0)/1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much faster! The only thing to note is that the time increment in an `aligned_windows` query is rounded to the nearest time increment that matches the inherent structure of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.89 hours\n"
     ]
    }
   ],
   "source": [
    "print(btrdb.utils.general.pointwidth(pw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However...\n",
    "\n",
    "Performance on `aligned_windows` queries is much faster, and will enable you to query data more quickly and at finer resolutions that you'll be able to do using `windows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.05 seconds\n"
     ]
    }
   ],
   "source": [
    "window = ns_delta(hours=6)\n",
    "pw = np.log2(window)\n",
    "\n",
    "t0 = currently_as_ns()\n",
    "statpoints = stream.aligned_windows(start.time, end.time, pointwidth=pw)\n",
    "print('Runtime: %.2f seconds'%((currently_as_ns()-t0)/1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 1.74 seconds\n"
     ]
    }
   ],
   "source": [
    "window = ns_delta(minutes=30)\n",
    "pw = np.log2(window)\n",
    "\n",
    "t0 = currently_as_ns()\n",
    "statpoints = stream.aligned_windows(start.time, end.time, pointwidth=pw)\n",
    "print('Runtime: %.2f seconds'%((currently_as_ns()-t0)/1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 60.34 seconds\n"
     ]
    }
   ],
   "source": [
    "window = ns_delta(minutes=1)\n",
    "pw = np.log2(window)\n",
    "\n",
    "t0 = currently_as_ns()\n",
    "statpoints = stream.aligned_windows(start.time, end.time, pointwidth=pw)\n",
    "print('Runtime: %.2f seconds'%((currently_as_ns()-t0)/1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That last query took a while! Let's make note of that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note to self: Don't try to query 561 days of data at 35 second granularity\n"
     ]
    }
   ],
   "source": [
    "dt = (end.time-start.time)/1e9/3600/24\n",
    "pw = btrdb.utils.general.pointwidth(pw)\n",
    "print(\"Note to self: Don't try to query %i days of data at %i second granularity\"%(dt, pw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When to use `values`\n",
    "\n",
    "Many analytics can be done using StatPoints to summarize steady state characteristics of the data at the time-scale that is of interest, or to identify intervals in the data where there is an \"event\" in the data. \n",
    "\n",
    "Here, we'll simply explore at what point values queries become intractable to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.27 seconds\n"
     ]
    }
   ],
   "source": [
    "window = ns_delta(minutes=1)\n",
    "start_time = start.time\n",
    "end_time = start_time + window\n",
    "\n",
    "t0 = currently_as_ns()\n",
    "statpoints = stream.values(start_time, end_time)\n",
    "print('Runtime: %.2f seconds'%((currently_as_ns()-t0)/1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.23 seconds\n"
     ]
    }
   ],
   "source": [
    "window = ns_delta(minutes=10)\n",
    "start_time = start.time\n",
    "end_time = start_time + window\n",
    "\n",
    "t0 = currently_as_ns()\n",
    "statpoints = stream.values(start_time, end_time)\n",
    "print('Runtime: %.2f seconds'%((currently_as_ns()-t0)/1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 1.15 seconds\n"
     ]
    }
   ],
   "source": [
    "window = ns_delta(hours=1)\n",
    "start_time = start.time\n",
    "end_time = start_time + window\n",
    "\n",
    "t0 = currently_as_ns()\n",
    "statpoints = stream.values(start_time, end_time)\n",
    "print('Runtime: %.2f seconds'%((currently_as_ns()-t0)/1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 6.86 seconds\n"
     ]
    }
   ],
   "source": [
    "window = ns_delta(hours=6)\n",
    "start_time = start.time\n",
    "end_time = start_time + window\n",
    "\n",
    "t0 = currently_as_ns()\n",
    "statpoints = stream.values(start_time, end_time)\n",
    "print('Runtime: %.2f seconds'%((currently_as_ns()-t0)/1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final note to self...\n",
    "\n",
    "When running values queries, be sure to check how much working memory you have available in your jupyterhub instance. Bringing large amounts of data into memory can easily crash your jupyter server! You may need to shut down and move to a larger instance if your kernel crashes repeatedly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `aligned_windows` queries in action \n",
    "Here are some examples where we use statpoints to hone in on time intervals that are known (or likely) to be of interest for a given analytic:\n",
    "- Voltage sags: https://github.com/PingThingsIO/ni4ai-notebooks/blob/main/demo/Voltage%20Sag%20Exploration.ipynb\n",
    "- Tap changes: https://github.com/PingThingsIO/ni4ai-notebooks/blob/main/demo/Voltage%20Change%20Detection.ipynb\n",
    "\n",
    "### `values` queries in action\n",
    "\n",
    "Here are examples where we use values queries to examine events that warrant full-resolution queries:\n",
    "- Spectral analysis: https://github.com/PingThingsIO/ni4ai-notebooks/blob/main/demo/PV_spectrogram.ipynb\n",
    "- Phase angle differencing: https://github.com/PingThingsIO/ni4ai-notebooks/blob/main/demo/Phase%20Angle%20Monitoring.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

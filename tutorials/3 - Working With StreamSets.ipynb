{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with StreamSets\n",
    "\n",
    "In this notebook we will focus on retrieving data from groups of time series streams (a `StreamSet`) as opposed to concentrating on individual streams.  You can think of a `StreamSet` as a wrapper around a list of `Stream` objects as found in the preceding notebook.\n",
    "\n",
    "The StreamSet class has a number of methods to mirror those found in regular Stream objects including methods for transforming and serializing the data to different formats. \n",
    "\n",
    "As with a `Stream`, retrieving data from the BTrDB server will fully materialize in memory so please keep this in mind.  In other words, do not attempt to retreive data that is greater than the amount of memory available to you.\n",
    "\n",
    "If you would like to learn more about any of the topics covered here, please see the btrdb library [documentation](https://btrdb.readthedocs.io/en/develop/index.html).\n",
    "\n",
    "**NOTE**: To get access to the Sunshine dataset to run this notebook, please register for an API key at [ni4ai.org](https://ni4ai.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import btrdb\n",
    "import yaml\n",
    "from tabulate import tabulate\n",
    "from btrdb.utils.timez import ns_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect To Server\n",
    "\n",
    "To get started we'll connect to the server and define a helper method from a previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'majorVersion': 5, 'build': '5.11.37', 'proxy': {'proxyEndpoints': []}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure you add your API key to the config file to connect!\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "conn = btrdb.connect(config['connection']['api_url'], config['connection']['api_key'])\n",
    "conn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_streams(streams):\n",
    "    table = [[\"Collection\", \"Name\", \"Units\", \"Version\", \"Earliest\", \"Latest\"]]\n",
    "    for stream in streams:\n",
    "        tags = stream.tags()\n",
    "        table.append([\n",
    "            stream.collection, stream.name, tags[\"unit\"], stream.version(), \n",
    "            stream.earliest()[0].time, stream.latest()[0].time, \n",
    "        ])\n",
    "    return tabulate(table, headers=\"firstrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Methods\n",
    "\n",
    "The best way to think about the `StreamSet` is as a wrapper around a list of `Stream` objects with appropriate methods added to help with examining your data. To create a `StreamSet` we first need the UUIDs for streams, which we will obtain by selecting a few voltage streams from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection     Name    Units      Version             Earliest               Latest\n",
      "-------------  ------  -------  ---------  -------------------  -------------------\n",
      "sunshine/PMU2  C2MAG   amps         19018  1456790400008333000  1464738948999999000\n",
      "sunshine/PMU2  C1MAG   amps         19018  1456790400008333000  1464738948999999000\n",
      "sunshine/PMU2  C3MAG   amps         19018  1456790400008333000  1464738948999999000\n"
     ]
    }
   ],
   "source": [
    "streams = conn.streams_in_collection('sunshine/PMU2', tags={\"unit\": \"amps\"})\n",
    "streams = list(streams)\n",
    "print(describe_streams(streams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a `StreamSet` using the UUIDs from our known streams.  In the future, we will be able to query based on collection, tags, etc., but for now we need to provide the UUIDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UUID('7925a0be-536e-44f0-875b-e176a7412f14'),\n",
       " UUID('a6df7f78-5b6d-4036-a7ef-4de95d04a53e'),\n",
       " UUID('9cc07564-7fa2-4961-8cda-1bb4f469317d')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UUIDs = [s.uuid for s in streams]\n",
    "UUIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StreamSet(3 streams)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset = conn.streams(*UUIDs)\n",
    "streamset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a StreamSet with the four streams, let's take a look at some of the helper methods.  In a Stream object, the `earliest` method would provide the first point in the Stream.  `StreamSet.earliest` will provide a tuple containing the first points from each individual stream.  The order is the same as the UUIDs that were provided when creating the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RawPoint(1456790400008333000, 115.00888061523438),\n",
       " RawPoint(1456790400008333000, 115.58443450927734),\n",
       " RawPoint(1456790400008333000, 104.03299713134766))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset.earliest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, let's look at the latest points in the streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RawPoint(1464738948999999000, 94.16214752197266),\n",
       " RawPoint(1464738948999999000, 99.10070037841797),\n",
       " RawPoint(1464738948999999000, 89.8238525390625))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset.latest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing Data\n",
    "\n",
    "Like the `Stream` object, the `StreamSet` has a `values` method which will return a list of lists.  Each internal list contains the `RawPoint` instances for a given stream.  Just as before we will return only a little bit of the data from the beginning of the streams.\n",
    "\n",
    "We will start by finding the earliest time from all of the earliest points although in this case they all have the same beginning time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1456790400008333000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliest_point = sorted(streamset.earliest(), key=lambda p: p.time)[0]\n",
    "earliest_point.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will ask for the values in the streams. Stream values are returned as a list of list of points such that the lists of points are ordered according to the UUIDs provided on initialization. Using this method data is fetched for each stream and returned and can be thought of as a helper method to query multiple streams simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[RawPoint(1456790400008333000, 115.00888061523438),\n",
       "  RawPoint(1456790400016666000, 114.9324722290039),\n",
       "  RawPoint(1456790400024999000, 115.0665512084961),\n",
       "  RawPoint(1456790400033333000, 115.17729949951172),\n",
       "  RawPoint(1456790400041666000, 114.99266815185547),\n",
       "  RawPoint(1456790400049999000, 114.45643615722656),\n",
       "  RawPoint(1456790400058333000, 113.85437774658203),\n",
       "  RawPoint(1456790400066666000, 113.72930145263672),\n",
       "  RawPoint(1456790400074999000, 113.93565368652344),\n",
       "  RawPoint(1456790400083333000, 113.95361328125),\n",
       "  RawPoint(1456790400091666000, 113.69194030761719),\n",
       "  RawPoint(1456790400099999000, 113.29793548583984)],\n",
       " [RawPoint(1456790400008333000, 115.58443450927734),\n",
       "  RawPoint(1456790400016666000, 115.8336410522461),\n",
       "  RawPoint(1456790400024999000, 116.0658950805664),\n",
       "  RawPoint(1456790400033333000, 115.89474487304688),\n",
       "  RawPoint(1456790400041666000, 115.30825805664062),\n",
       "  RawPoint(1456790400049999000, 114.27113342285156),\n",
       "  RawPoint(1456790400058333000, 113.3078842163086),\n",
       "  RawPoint(1456790400066666000, 113.05310821533203),\n",
       "  RawPoint(1456790400074999000, 113.1114730834961),\n",
       "  RawPoint(1456790400083333000, 113.04302215576172),\n",
       "  RawPoint(1456790400091666000, 112.81172180175781),\n",
       "  RawPoint(1456790400099999000, 112.50586700439453)],\n",
       " [RawPoint(1456790400008333000, 104.03299713134766),\n",
       "  RawPoint(1456790400016666000, 103.94195556640625),\n",
       "  RawPoint(1456790400024999000, 103.55602264404297),\n",
       "  RawPoint(1456790400033333000, 103.05726623535156),\n",
       "  RawPoint(1456790400041666000, 102.64067840576172),\n",
       "  RawPoint(1456790400049999000, 102.25871276855469),\n",
       "  RawPoint(1456790400058333000, 102.02741241455078),\n",
       "  RawPoint(1456790400066666000, 102.04944610595703),\n",
       "  RawPoint(1456790400074999000, 102.06348419189453),\n",
       "  RawPoint(1456790400083333000, 101.94192504882812),\n",
       "  RawPoint(1456790400091666000, 101.87135314941406),\n",
       "  RawPoint(1456790400099999000, 101.87373352050781)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = earliest_point.time\n",
    "end = start + ns_delta(milliseconds=100)\n",
    "streamset.filter(start, end).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that we first called the `filter` method and then called the `values` method with no arguments.  The `StreamSet` class was designed to support a method chaining style of programming and so behaves slightly differently from the `Stream`.\n",
    "\n",
    "Data is only ever materialized when calling the `values` or `rows` method as demonstrated below.  The `rows` method is similar to the `values` method but orients the data differently.  Here you will notice that the streams are aligned according to time.  The first tuple contains all of the data for the first time index.  If any streams do not have data at that time index, then `None` is used as a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(RawPoint(1456790400008333000, 115.00888061523438),\n",
       "  RawPoint(1456790400008333000, 115.58443450927734),\n",
       "  RawPoint(1456790400008333000, 104.03299713134766)),\n",
       " (RawPoint(1456790400016666000, 114.9324722290039),\n",
       "  RawPoint(1456790400016666000, 115.8336410522461),\n",
       "  RawPoint(1456790400016666000, 103.94195556640625)),\n",
       " (RawPoint(1456790400024999000, 115.0665512084961),\n",
       "  RawPoint(1456790400024999000, 116.0658950805664),\n",
       "  RawPoint(1456790400024999000, 103.55602264404297)),\n",
       " (RawPoint(1456790400033333000, 115.17729949951172),\n",
       "  RawPoint(1456790400033333000, 115.89474487304688),\n",
       "  RawPoint(1456790400033333000, 103.05726623535156)),\n",
       " (RawPoint(1456790400041666000, 114.99266815185547),\n",
       "  RawPoint(1456790400041666000, 115.30825805664062),\n",
       "  RawPoint(1456790400041666000, 102.64067840576172)),\n",
       " (RawPoint(1456790400049999000, 114.45643615722656),\n",
       "  RawPoint(1456790400049999000, 114.27113342285156),\n",
       "  RawPoint(1456790400049999000, 102.25871276855469)),\n",
       " (RawPoint(1456790400058333000, 113.85437774658203),\n",
       "  RawPoint(1456790400058333000, 113.3078842163086),\n",
       "  RawPoint(1456790400058333000, 102.02741241455078)),\n",
       " (RawPoint(1456790400066666000, 113.72930145263672),\n",
       "  RawPoint(1456790400066666000, 113.05310821533203),\n",
       "  RawPoint(1456790400066666000, 102.04944610595703)),\n",
       " (RawPoint(1456790400074999000, 113.93565368652344),\n",
       "  RawPoint(1456790400074999000, 113.1114730834961),\n",
       "  RawPoint(1456790400074999000, 102.06348419189453)),\n",
       " (RawPoint(1456790400083333000, 113.95361328125),\n",
       "  RawPoint(1456790400083333000, 113.04302215576172),\n",
       "  RawPoint(1456790400083333000, 101.94192504882812)),\n",
       " (RawPoint(1456790400091666000, 113.69194030761719),\n",
       "  RawPoint(1456790400091666000, 112.81172180175781),\n",
       "  RawPoint(1456790400091666000, 101.87135314941406)),\n",
       " (RawPoint(1456790400099999000, 113.29793548583984),\n",
       "  RawPoint(1456790400099999000, 112.50586700439453),\n",
       "  RawPoint(1456790400099999000, 101.87373352050781))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset.filter(start, end).rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the tabulate library again to better format the data rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               time    C2MAG    C1MAG    C3MAG\n",
      "-------------------  -------  -------  -------\n",
      "1456790400008333000  115.009  115.584  104.033\n",
      "1456790400016666000  114.932  115.834  103.942\n",
      "1456790400024999000  115.067  116.066  103.556\n",
      "1456790400033333000  115.177  115.895  103.057\n",
      "1456790400041666000  114.993  115.308  102.641\n",
      "1456790400049999000  114.456  114.271  102.259\n",
      "1456790400058333000  113.854  113.308  102.027\n",
      "1456790400066666000  113.729  113.053  102.049\n",
      "1456790400074999000  113.936  113.111  102.063\n",
      "1456790400083333000  113.954  113.043  101.942\n",
      "1456790400091666000  113.692  112.812  101.871\n",
      "1456790400099999000  113.298  112.506  101.874\n"
     ]
    }
   ],
   "source": [
    "table = [[\"time\"] + [s.name for s in streamset]]\n",
    "\n",
    "for row in streamset.filter(start, end).rows():\n",
    "    time = sorted([p.time for p in row])[-1]\n",
    "    data = [time]\n",
    "    for point in row:\n",
    "        data.append(point.value)\n",
    "    table.append(data)\n",
    "        \n",
    "print(tabulate(table, headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Data to Other Formats\n",
    "\n",
    "A number of methods have been provided to convert the point data objects into objects you may already be familiar with such as numpy arrays and pandas dataframes.  Using these transformation methods materializes the data similar to the `values` method.  Examples of the available transformations follow.\n",
    "\n",
    "## Numpy Arrays\n",
    "\n",
    "Converting to Numpy arrays will produce a list of arrays.  This output will be similar in structure to calling the `values` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115.00888062, 114.93247223, 115.06655121, 115.1772995 ,\n",
       "        114.99266815, 114.45643616, 113.85437775, 113.72930145,\n",
       "        113.93565369, 113.95361328, 113.69194031, 113.29793549],\n",
       "       [115.58443451, 115.83364105, 116.06589508, 115.89474487,\n",
       "        115.30825806, 114.27113342, 113.30788422, 113.05310822,\n",
       "        113.11147308, 113.04302216, 112.8117218 , 112.505867  ],\n",
       "       [104.03299713, 103.94195557, 103.55602264, 103.05726624,\n",
       "        102.64067841, 102.25871277, 102.02741241, 102.04944611,\n",
       "        102.06348419, 101.94192505, 101.87135315, 101.87373352]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = earliest_point.time\n",
    "end = start + ns_delta(milliseconds=100)\n",
    "\n",
    "streamset.filter(start, end).to_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Series\n",
    "\n",
    "Converting to a pandas series will produce a view of the data similar to calling the `values` method.  The resulting series will be indexed by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2016-03-01 00:00:00.008333    115.008881\n",
       " 2016-03-01 00:00:00.016666    114.932472\n",
       " 2016-03-01 00:00:00.024999    115.066551\n",
       " 2016-03-01 00:00:00.033333    115.177299\n",
       " 2016-03-01 00:00:00.041666    114.992668\n",
       " 2016-03-01 00:00:00.049999    114.456436\n",
       " 2016-03-01 00:00:00.058333    113.854378\n",
       " 2016-03-01 00:00:00.066666    113.729301\n",
       " 2016-03-01 00:00:00.074999    113.935654\n",
       " 2016-03-01 00:00:00.083333    113.953613\n",
       " 2016-03-01 00:00:00.091666    113.691940\n",
       " 2016-03-01 00:00:00.099999    113.297935\n",
       " Name: sunshine/PMU2/C2MAG, dtype: float64,\n",
       " 2016-03-01 00:00:00.008333    115.584435\n",
       " 2016-03-01 00:00:00.016666    115.833641\n",
       " 2016-03-01 00:00:00.024999    116.065895\n",
       " 2016-03-01 00:00:00.033333    115.894745\n",
       " 2016-03-01 00:00:00.041666    115.308258\n",
       " 2016-03-01 00:00:00.049999    114.271133\n",
       " 2016-03-01 00:00:00.058333    113.307884\n",
       " 2016-03-01 00:00:00.066666    113.053108\n",
       " 2016-03-01 00:00:00.074999    113.111473\n",
       " 2016-03-01 00:00:00.083333    113.043022\n",
       " 2016-03-01 00:00:00.091666    112.811722\n",
       " 2016-03-01 00:00:00.099999    112.505867\n",
       " Name: sunshine/PMU2/C1MAG, dtype: float64,\n",
       " 2016-03-01 00:00:00.008333    104.032997\n",
       " 2016-03-01 00:00:00.016666    103.941956\n",
       " 2016-03-01 00:00:00.024999    103.556023\n",
       " 2016-03-01 00:00:00.033333    103.057266\n",
       " 2016-03-01 00:00:00.041666    102.640678\n",
       " 2016-03-01 00:00:00.049999    102.258713\n",
       " 2016-03-01 00:00:00.058333    102.027412\n",
       " 2016-03-01 00:00:00.066666    102.049446\n",
       " 2016-03-01 00:00:00.074999    102.063484\n",
       " 2016-03-01 00:00:00.083333    101.941925\n",
       " 2016-03-01 00:00:00.091666    101.871353\n",
       " 2016-03-01 00:00:00.099999    101.873734\n",
       " Name: sunshine/PMU2/C3MAG, dtype: float64]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset.filter(start, end).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrame\n",
    "\n",
    "Converting to a pandas dataframe will produce a tabular view of the data similar to calling the `rows` method.  The resulting dataframe will be indexed by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sunshine/PMU2/C2MAG</th>\n",
       "      <th>sunshine/PMU2/C1MAG</th>\n",
       "      <th>sunshine/PMU2/C3MAG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1456790400008333000</th>\n",
       "      <td>115.008881</td>\n",
       "      <td>115.584435</td>\n",
       "      <td>104.032997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456790400016666000</th>\n",
       "      <td>114.932472</td>\n",
       "      <td>115.833641</td>\n",
       "      <td>103.941956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456790400024999000</th>\n",
       "      <td>115.066551</td>\n",
       "      <td>116.065895</td>\n",
       "      <td>103.556023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456790400033333000</th>\n",
       "      <td>115.177299</td>\n",
       "      <td>115.894745</td>\n",
       "      <td>103.057266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456790400041666000</th>\n",
       "      <td>114.992668</td>\n",
       "      <td>115.308258</td>\n",
       "      <td>102.640678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456790400049999000</th>\n",
       "      <td>114.456436</td>\n",
       "      <td>114.271133</td>\n",
       "      <td>102.258713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456790400058333000</th>\n",
       "      <td>113.854378</td>\n",
       "      <td>113.307884</td>\n",
       "      <td>102.027412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456790400066666000</th>\n",
       "      <td>113.729301</td>\n",
       "      <td>113.053108</td>\n",
       "      <td>102.049446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456790400074999000</th>\n",
       "      <td>113.935654</td>\n",
       "      <td>113.111473</td>\n",
       "      <td>102.063484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456790400083333000</th>\n",
       "      <td>113.953613</td>\n",
       "      <td>113.043022</td>\n",
       "      <td>101.941925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456790400091666000</th>\n",
       "      <td>113.691940</td>\n",
       "      <td>112.811722</td>\n",
       "      <td>101.871353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456790400099999000</th>\n",
       "      <td>113.297935</td>\n",
       "      <td>112.505867</td>\n",
       "      <td>101.873734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sunshine/PMU2/C2MAG  sunshine/PMU2/C1MAG  \\\n",
       "time                                                            \n",
       "1456790400008333000           115.008881           115.584435   \n",
       "1456790400016666000           114.932472           115.833641   \n",
       "1456790400024999000           115.066551           116.065895   \n",
       "1456790400033333000           115.177299           115.894745   \n",
       "1456790400041666000           114.992668           115.308258   \n",
       "1456790400049999000           114.456436           114.271133   \n",
       "1456790400058333000           113.854378           113.307884   \n",
       "1456790400066666000           113.729301           113.053108   \n",
       "1456790400074999000           113.935654           113.111473   \n",
       "1456790400083333000           113.953613           113.043022   \n",
       "1456790400091666000           113.691940           112.811722   \n",
       "1456790400099999000           113.297935           112.505867   \n",
       "\n",
       "                     sunshine/PMU2/C3MAG  \n",
       "time                                      \n",
       "1456790400008333000           104.032997  \n",
       "1456790400016666000           103.941956  \n",
       "1456790400024999000           103.556023  \n",
       "1456790400033333000           103.057266  \n",
       "1456790400041666000           102.640678  \n",
       "1456790400049999000           102.258713  \n",
       "1456790400058333000           102.027412  \n",
       "1456790400066666000           102.049446  \n",
       "1456790400074999000           102.063484  \n",
       "1456790400083333000           101.941925  \n",
       "1456790400091666000           101.871353  \n",
       "1456790400099999000           101.873734  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset.filter(start, end).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Dictionaries\n",
    "\n",
    "Converting to Python dictionaries produces a list of `OrderedDicts` similar to calling the `rows` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('time', 1456790400008333000),\n",
       "              ('sunshine/PMU2/C2MAG', 115.00888061523438),\n",
       "              ('sunshine/PMU2/C1MAG', 115.58443450927734),\n",
       "              ('sunshine/PMU2/C3MAG', 104.03299713134766)]),\n",
       " OrderedDict([('time', 1456790400016666000),\n",
       "              ('sunshine/PMU2/C2MAG', 114.9324722290039),\n",
       "              ('sunshine/PMU2/C1MAG', 115.8336410522461),\n",
       "              ('sunshine/PMU2/C3MAG', 103.94195556640625)]),\n",
       " OrderedDict([('time', 1456790400024999000),\n",
       "              ('sunshine/PMU2/C2MAG', 115.0665512084961),\n",
       "              ('sunshine/PMU2/C1MAG', 116.0658950805664),\n",
       "              ('sunshine/PMU2/C3MAG', 103.55602264404297)]),\n",
       " OrderedDict([('time', 1456790400033333000),\n",
       "              ('sunshine/PMU2/C2MAG', 115.17729949951172),\n",
       "              ('sunshine/PMU2/C1MAG', 115.89474487304688),\n",
       "              ('sunshine/PMU2/C3MAG', 103.05726623535156)]),\n",
       " OrderedDict([('time', 1456790400041666000),\n",
       "              ('sunshine/PMU2/C2MAG', 114.99266815185547),\n",
       "              ('sunshine/PMU2/C1MAG', 115.30825805664062),\n",
       "              ('sunshine/PMU2/C3MAG', 102.64067840576172)]),\n",
       " OrderedDict([('time', 1456790400049999000),\n",
       "              ('sunshine/PMU2/C2MAG', 114.45643615722656),\n",
       "              ('sunshine/PMU2/C1MAG', 114.27113342285156),\n",
       "              ('sunshine/PMU2/C3MAG', 102.25871276855469)]),\n",
       " OrderedDict([('time', 1456790400058333000),\n",
       "              ('sunshine/PMU2/C2MAG', 113.85437774658203),\n",
       "              ('sunshine/PMU2/C1MAG', 113.3078842163086),\n",
       "              ('sunshine/PMU2/C3MAG', 102.02741241455078)]),\n",
       " OrderedDict([('time', 1456790400066666000),\n",
       "              ('sunshine/PMU2/C2MAG', 113.72930145263672),\n",
       "              ('sunshine/PMU2/C1MAG', 113.05310821533203),\n",
       "              ('sunshine/PMU2/C3MAG', 102.04944610595703)]),\n",
       " OrderedDict([('time', 1456790400074999000),\n",
       "              ('sunshine/PMU2/C2MAG', 113.93565368652344),\n",
       "              ('sunshine/PMU2/C1MAG', 113.1114730834961),\n",
       "              ('sunshine/PMU2/C3MAG', 102.06348419189453)]),\n",
       " OrderedDict([('time', 1456790400083333000),\n",
       "              ('sunshine/PMU2/C2MAG', 113.95361328125),\n",
       "              ('sunshine/PMU2/C1MAG', 113.04302215576172),\n",
       "              ('sunshine/PMU2/C3MAG', 101.94192504882812)]),\n",
       " OrderedDict([('time', 1456790400091666000),\n",
       "              ('sunshine/PMU2/C2MAG', 113.69194030761719),\n",
       "              ('sunshine/PMU2/C1MAG', 112.81172180175781),\n",
       "              ('sunshine/PMU2/C3MAG', 101.87135314941406)]),\n",
       " OrderedDict([('time', 1456790400099999000),\n",
       "              ('sunshine/PMU2/C2MAG', 113.29793548583984),\n",
       "              ('sunshine/PMU2/C1MAG', 112.50586700439453),\n",
       "              ('sunshine/PMU2/C3MAG', 101.87373352050781)])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamset.filter(start, end).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serializing Data\n",
    "\n",
    "Aside from transforming to other data objects, you can also serialize the data to other formats.  At the moment, you can serialize the data a string for display.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               time    sunshine/PMU2/C2MAG    sunshine/PMU2/C1MAG\n",
      "-------------------  ---------------------  ---------------------\n",
      "1456790400008333000                115.009                115.584\n",
      "1456790400016666000                114.932                115.834\n",
      "1456790400024999000                115.067                116.066\n",
      "1456790400033333000                115.177                115.895\n",
      "1456790400041666000                114.993                115.308\n",
      "1456790400049999000                114.456                114.271\n",
      "1456790400058333000                113.854                113.308\n",
      "1456790400066666000                113.729                113.053\n",
      "1456790400074999000                113.936                113.111\n",
      "1456790400083333000                113.954                113.043\n",
      "1456790400091666000                113.692                112.812\n",
      "1456790400099999000                113.298                112.506\n"
     ]
    }
   ],
   "source": [
    "# create a new streamset with only 2 streams for better display in a notebook\n",
    "streamset = conn.streams(*UUIDs[:2])\n",
    "\n",
    "# call to_csv which will detect the output stream and write the data to it\n",
    "print(streamset.filter(start, end).to_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
